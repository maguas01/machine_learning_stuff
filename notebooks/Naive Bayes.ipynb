{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naives Bayes \n",
    "\n",
    "- prior : all that can be infered about a situation\n",
    "- posterior : an inference made after gaining new information\n",
    "- bayes theorem: is about the probability about some event $P(A)$ we introduce some event that is related to A $P(R|A)$ bayes theorem infers the probability of A given R $P(A|R)$\n",
    "\n",
    ".6, prob that brenda did not wear red is .4 we can put these together and get\n",
    "\n",
    "![bayes0](img/bayes0.png)\n",
    "\n",
    "![](img/bayes1.png)\n",
    "\n",
    "## Naive Bayes Example\n",
    "- this theorem is best explained using an example. \n",
    "![](img/bayes2.png)\n",
    "\n",
    "\n",
    "supposed we have recieved these emails 3 spam and 5 not spam, call the not spam ham. \n",
    "we can figure out the probability of an email being spam $P(spam) =\\frac{3}{8}$ and ham $P(ham) =\\frac{5}{8}$. \n",
    "\n",
    "now we look at the spam emails $\\frac{1}{3}$ of them have the word 'easy' in them and th rest dont, so $\\frac{2}{3}$ next we can figure out the probability that an email is spam given it containts the word 'easy' $P(spam|'easy')=\\frac{1}{3}*\\frac{3}{8}=\\frac{1}{8}$ and $P(spam|'easy'^c)=\\frac{2}{3}*\\frac{3}{8}=\\frac{1}{4}$\n",
    "we do the same for ham $\\frac{1}{5}$ contained the word 'easy' and $\\frac{4}{5}$ did not contain the word 'easy' and were ham, we get that $P(ham|'easy') = \\frac{5}{8}*\\frac{1}{5}=\\frac{1}{8}$ and $P(ham|'easy'^c) = \\frac{5}{8}*\\frac{4}{5}=\\frac{1}{2}$\n",
    "\n",
    "we can do the same for the word money $P(spam|'money')= \\frac{1}{4}$,  $P(spam|'money'^c) = \\frac{1}{4}$, $P(spam|'money')= \\frac{1}{8}$ and $P(ham|'money'^c)= \\frac{1}{2}$\n",
    "\n",
    "these are things we know spam emails that contain the word 'easy' or 'money'. We wish to infer if an email contains the word 'easy' or 'money' is it spam. In other words we know $P(spam|'easy')$ and wish to infer $P('easy'|spam)$\n",
    "\n",
    "we can do this with Naive Bayes theorem, we take the event that wish to know about and normalize it\n",
    "\n",
    "$P('easy'|spam)=\\frac{P(spam|'easy')}{P(spam|'easy') + P(ham|'easy')}=\\frac{\\frac{1}{8}}{\\frac{1}{8} + \\frac{1}{8}}=\\frac{1}{2}$\n",
    "\n",
    "$P('easy'|ham)=\\frac{1}{2}$\n",
    "\n",
    "$P('money'|spam) = \\frac{2}{3}$\n",
    "\n",
    "$P('money'|ham) = \\frac{1}{3}$\n",
    "\n",
    "## Naive Bayes Algorithm \n",
    "\n",
    "first lets remember that $P(A \\& B) = P(A \\cap B) = P(A)P(B)$ iff A and B are independent and $P(A|B)P(B) = P(B|A)P(A)$ and $P(A|B)\\propto P(B|A)P(A)$\n",
    "\n",
    "we can use this, we know $P(spam|'easy', 'money')$ and know that it is proportional to $P('easy','money'|spam)P(spam)$ that is to say : \n",
    "\n",
    "$P(spam|'easy', 'money') \\propto P('easy','money'|spam)P(spam) \\\\\n",
    " P(spam|'easy', 'money') \\propto P('easy'|spam)P('money'|spam)P(spam)\\\\\n",
    " P(spam|'easy', 'money') \\propto \\frac{1}{3}*\\frac{2}{3}*\\frac{3}{8} \\\\\n",
    " P(spam|'easy', 'money') \\propto \\frac{1}{12}$\n",
    " \n",
    " similarly $P(ham|'easy', 'money') \\propto \\frac{1}{40}$\n",
    " \n",
    "now we know $P(spam|'easy', 'money')$ and can infer $P('easy', 'money'|spam)$ and $P(ham|'easy', 'money')$ and can infer $P('easy', 'money'|ham)$\n",
    "\n",
    "$P('easy', 'money'|spam) = \\frac{P(spam|'easy', 'money')}{P(spam|'easy', 'money') + P(ham|'easy', 'money')} \\\\ \n",
    " P('easy', 'money'|spam) = \\frac{\\frac{1}{12}}{\\frac{1}{12}\\frac{1}{40}}\\\\\n",
    " P('easy', 'money'|spam) = \\frac{10}{13}$\n",
    " \n",
    " similarly $P('easy', 'money'| ham) = \\frac{3}{13}$\n",
    " \n",
    "From this example we can see that if we wish to look for the probability of an email being spam or not given some list of words $w_1, w_2, ..., w_n$  \n",
    "\n",
    "find<br\\>\n",
    "$P(spam|w_1,w_2,..., w_n) \\propto P(w_1,w_2,...,w_n|spam) \\\\ \n",
    " P(spam|w_1,w_2,..., w_n) \\propto P(w_1|spam)P(w_2|spam)*...*P(w_n|spam)P(spam)$\n",
    " \n",
    "then<br\\>\n",
    "$P(ham|w_1,w_2,..., w_n) \\propto P(w_1,w_2,...,w_n|ham) \\\\ \n",
    " P(ham|w_1,w_2,..., w_n) \\propto P(w_1|ham)P(w_2|ham)*...*P(w_n|ham)P(ham)$\n",
    " \n",
    "and normalize: <br/>\n",
    "prob spam <br/>\n",
    "$\\frac{P(w_1|spam)P(w_2|spam)*...*P(w_n|spam)P(spam)}{P(w_1|spam)P(w_2|spam)*...*P(w_n|spam)P(spam)+ P(w_1|ham)P(w_2|ham)*...*P(w_n|ham)P(ham)}$\n",
    "\n",
    "prob ham<br/>\n",
    "$\\frac{P(w_1|ham)P(w_2|ham)*...*P(w_n|ham)P(ham)}{P(w_1|spam)P(w_2|spam)*...*P(w_n|spam)P(spam)+ P(w_1|ham)P(w_2|ham)*...*P(w_n|ham)P(ham)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
